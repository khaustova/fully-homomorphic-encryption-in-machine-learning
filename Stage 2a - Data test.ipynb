{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение задачи прогнозирования задолженности по услугам ЖКХ с использованием полностью гомоморфного шифрования\n",
    "### Этап 2a - Исследование влияние размера данных на производительность полностью гомоморфного шифрования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tenseal as ts\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Обучение на незашифрованных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим набор данных на выборки с разным объёмом: 4400, 3400, 2400, 1400 и 400 объектов соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('data.csv', low_memory=False) # (4400, 23) \n",
    "\n",
    "df_2 = df_1.sample(frac=0.7727) # (3400, 23)\n",
    "\n",
    "df_3 = df_1.sample(frac=0.5455) # (2400, 23)\n",
    "\n",
    "df_4 = df_1.sample(frac=0.3182) # (1400, 23)\n",
    "\n",
    "df_5 = df_1.sample(frac=0.091) # (400, 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также разделим набор данных на выборки с разным количество признаков: 23, 21, 19, 17 и 15 соответственно.  \n",
    "За основу возьмём выборку df_4 размером 1400 на 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 17)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_6 = df_4.copy()\n",
    "df_6 = df_6.drop(columns=[\n",
    "    \"Age\",\n",
    "    \"Family_Size\"\n",
    "]) # (1400, 21)\n",
    "\n",
    "df_7 = df_6.copy()\n",
    "df_7 = df_7.drop(columns=[\n",
    "    \"Number_of_Children\",\n",
    "    \"Residence_Type\"\n",
    "]) # (1400, 19)\n",
    "\n",
    "df_8 = df_7.copy()\n",
    "df_8 = df_8.drop(columns=[\n",
    "    \"Frequency_of_Mobile_App_Usage\", \n",
    "    \"Payment_Method\",\n",
    "]) # (1400, 17)\n",
    "\n",
    "df_9 = df_8.copy()\n",
    "df_9 = df_9.drop(columns=[\n",
    "    \"Seasonal_Factors\", \n",
    "    \"Email_Notifications_Opt_In\",\n",
    "]) # (1400, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на тестовые и обучающие выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(df):\n",
    "    x = df.drop(columns=['Is_Delinquent'])\n",
    "    y = df['Is_Delinquent'].copy()\n",
    "\n",
    "    return train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_train, x_1_test, y_1_train, y_1_test = get_train_test_split(df_1)\n",
    "x_2_train, x_2_test, y_2_train, y_2_test = get_train_test_split(df_2)\n",
    "x_3_train, x_3_test, y_3_train, y_3_test = get_train_test_split(df_3)\n",
    "x_4_train, x_4_test, y_4_train, y_4_test = get_train_test_split(df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_5_train, x_5_test, y_5_train, y_5_test = get_train_test_split(df_5)\n",
    "x_6_train, x_6_test, y_6_train, y_6_test = get_train_test_split(df_6)\n",
    "x_7_train, x_7_test, y_7_train, y_7_test = get_train_test_split(df_7)\n",
    "x_8_train, x_8_test, y_8_train, y_8_test = get_train_test_split(df_8)\n",
    "x_9_train, x_9_test, y_9_train, y_9_test = get_train_test_split(df_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим тензоры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_train = torch.tensor(x_1_train.values).to(torch.float32)\n",
    "x_1_test = torch.tensor(x_1_test.values).to(torch.float32)\n",
    "\n",
    "x_2_train = torch.tensor(x_2_train.values).to(torch.float32)\n",
    "x_2_test = torch.tensor(x_2_test.values).to(torch.float32)\n",
    "\n",
    "x_3_train = torch.tensor(x_3_train.values).to(torch.float32)\n",
    "x_3_test = torch.tensor(x_3_test.values).to(torch.float32)\n",
    "\n",
    "x_4_train = torch.tensor(x_4_train.values).to(torch.float32)\n",
    "x_4_test = torch.tensor(x_4_test.values).to(torch.float32)\n",
    "\n",
    "x_5_train = torch.tensor(x_5_train.values).to(torch.float32)\n",
    "x_5_test = torch.tensor(x_5_test.values).to(torch.float32)\n",
    "\n",
    "x_6_train = torch.tensor(x_6_train.values).to(torch.float32)\n",
    "x_6_test = torch.tensor(x_6_test.values).to(torch.float32)\n",
    "\n",
    "x_7_train = torch.tensor(x_7_train.values).to(torch.float32)\n",
    "x_7_test = torch.tensor(x_7_test.values).to(torch.float32)\n",
    "\n",
    "x_8_train = torch.tensor(x_8_train.values).to(torch.float32)\n",
    "x_8_test = torch.tensor(x_8_test.values).to(torch.float32)\n",
    "\n",
    "x_9_train = torch.tensor(x_9_train.values).to(torch.float32)\n",
    "x_9_test = torch.tensor(x_9_test.values).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1_train = torch.tensor(y_1_train.values).to(torch.float32).unsqueeze(1)\n",
    "y_1_test = torch.tensor(y_1_test.values).to(torch.float32).unsqueeze(1)\n",
    "\n",
    "y_2_train = torch.tensor(y_2_train.values).to(torch.float32).unsqueeze(1)\n",
    "y_2_test = torch.tensor(y_2_test.values).to(torch.float32).unsqueeze(1)\n",
    "\n",
    "y_3_train = torch.tensor(y_3_train.values).to(torch.float32).unsqueeze(1)\n",
    "y_3_test = torch.tensor(y_3_test.values).to(torch.float32).unsqueeze(1)\n",
    "\n",
    "y_4_train = torch.tensor(y_4_train.values).to(torch.float32).unsqueeze(1)\n",
    "y_4_test = torch.tensor(y_4_test.values).to(torch.float32).unsqueeze(1)\n",
    "\n",
    "y_5_train = torch.tensor(y_5_train.values).to(torch.float32).unsqueeze(1)\n",
    "y_5_test = torch.tensor(y_5_test.values).to(torch.float32).unsqueeze(1)\n",
    "\n",
    "y_6_train = torch.tensor(y_6_train.values).to(torch.float32).unsqueeze(1)\n",
    "y_6_test = torch.tensor(y_6_test.values).to(torch.float32).unsqueeze(1)\n",
    "\n",
    "y_7_train = torch.tensor(y_7_train.values).to(torch.float32).unsqueeze(1)\n",
    "y_7_test = torch.tensor(y_7_test.values).to(torch.float32).unsqueeze(1)\n",
    "\n",
    "y_8_train = torch.tensor(y_8_train.values).to(torch.float32).unsqueeze(1)\n",
    "y_8_test = torch.tensor(y_8_test.values).to(torch.float32).unsqueeze(1)\n",
    "\n",
    "y_9_train = torch.tensor(y_9_train.values).to(torch.float32).unsqueeze(1)\n",
    "y_9_test = torch.tensor(y_9_test.values).to(torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим модель логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "def train(model, optim, criterion, x, y, data_name, epochs=EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "def accuracy(model, x, y, data_name):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    plain_accuracy = correct.float().mean()\n",
    "    print(f'Точность модели обученной на незашифрованных данных {data_name}: {plain_accuracy}')\n",
    "    return plain_accuracy\n",
    "\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на выборках, разделённых по количеству объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели обученной на незашифрованных данных \"Набор 1\": 0.8602272868156433\n"
     ]
    }
   ],
   "source": [
    "n_1 = x_1_train.shape[1]\n",
    "lr_1 = LogisticRegression(n_1)\n",
    "optim_1 = torch.optim.SGD(lr_1.parameters(), lr=1)\n",
    "model_1 = train(lr_1, optim_1, criterion, x_1_train, y_1_train, '\"Набор 1\"')\n",
    "plain_accuracy_1 = accuracy(model_1, x_1_test, y_1_test, '\"Набор 1\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели обученной на незашифрованных данных \"Набор 2\": 0.8661764860153198\n"
     ]
    }
   ],
   "source": [
    "n_2 = x_2_train.shape[1] \n",
    "lr_2 = LogisticRegression(n_2)\n",
    "optim_2 = torch.optim.SGD(lr_2.parameters(), lr=1)\n",
    "model_2 = train(lr_2, optim_2, criterion, x_2_train, y_2_train, '\"Набор 2\"')\n",
    "plain_accuracy_2 = accuracy(model_2, x_2_test, y_2_test, '\"Набор 2\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели обученной на незашифрованных данных \"Набор 3\": 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "n_3 = x_3_train.shape[1]\n",
    "lr_3 = LogisticRegression(n_3)\n",
    "optim_3 = torch.optim.SGD(lr_3.parameters(), lr=1)\n",
    "model_3 = train(lr_3, optim_3, criterion, x_3_train, y_3_train, '\"Набор 3\"')\n",
    "plain_accuracy_3 = accuracy(model_3, x_3_test, y_3_test, '\"Набор 3\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели обученной на незашифрованных данных \"Набор 4\": 0.8571428656578064\n"
     ]
    }
   ],
   "source": [
    "n_4 = x_4_train.shape[1]\n",
    "lr_4 = LogisticRegression(n_4)\n",
    "optim_4 = torch.optim.SGD(lr_4.parameters(), lr=1)\n",
    "model_4 = train(lr_4, optim_4, criterion, x_4_train, y_4_train, '\"Набор 4\"')\n",
    "plain_accuracy_4 = accuracy(model_4, x_4_test, y_4_test, '\"Набор 4\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели обученной на незашифрованных данных \"Набор 5\": 0.8374999761581421\n"
     ]
    }
   ],
   "source": [
    "n_5 = x_5_train.shape[1]\n",
    "lr_5 = LogisticRegression(n_5)\n",
    "optim_5 = torch.optim.SGD(lr_5.parameters(), lr=1)\n",
    "model_5 = train(lr_5, optim_5, criterion, x_5_train, y_5_train, '\"Набор 5\"')\n",
    "plain_accuracy_5 = accuracy(model_5, x_5_test, y_5_test, '\"Набор 5\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на выборках, разделённых по количеству признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели обученной на незашифрованных данных \"Набор 6\": 0.8464285731315613\n"
     ]
    }
   ],
   "source": [
    "n_6 = x_6_train.shape[1]\n",
    "lr_6 = LogisticRegression(n_6)\n",
    "optim_6 = torch.optim.SGD(lr_6.parameters(), lr=1)\n",
    "model_6 = train(lr_6, optim_6, criterion, x_6_train, y_6_train, '\"Набор 6\"')\n",
    "plain_accuracy_6 = accuracy(model_6, x_6_test, y_6_test, '\"Набор 6\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели обученной на незашифрованных данных \"Набор 7\": 0.8714285492897034\n"
     ]
    }
   ],
   "source": [
    "n_7 = x_7_train.shape[1] \n",
    "lr_7 = LogisticRegression(n_7)\n",
    "optim_7 = torch.optim.SGD(lr_7.parameters(), lr=1)\n",
    "model_7 = train(lr_7, optim_7, criterion, x_7_train, y_7_train, '\"Набор 7\"')\n",
    "plain_accuracy_7 = accuracy(model_7, x_7_test, y_7_test, '\"Набор 7\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели обученной на незашифрованных данных \"Набор 8\": 0.8714285492897034\n"
     ]
    }
   ],
   "source": [
    "n_8 = x_8_train.shape[1]\n",
    "lr_8 = LogisticRegression(n_8)\n",
    "optim_8 = torch.optim.SGD(lr_8.parameters(), lr=1)\n",
    "model_8 = train(lr_8, optim_8, criterion, x_8_train, y_8_train, '\"Набор 8\"')\n",
    "plain_accuracy_8 = accuracy(model_8, x_8_test, y_8_test, '\"Набор 8\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели обученной на незашифрованных данных \"Набор 9\": 0.8714285492897034\n"
     ]
    }
   ],
   "source": [
    "n_9 = x_9_train.shape[1]\n",
    "lr_9 = LogisticRegression(n_9)\n",
    "optim_9 = torch.optim.SGD(lr_9.parameters(), lr=1)\n",
    "model_9 = train(lr_9, optim_9, criterion, x_9_train, y_9_train, '\"Набор 9\"')\n",
    "plain_accuracy_9 = accuracy(model_9, x_9_test, y_9_test, '\"Набор 9\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Обучение на зашифрованных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_mod_grade = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_grade, -1, coeff_mod_bit_sizes)\n",
    "ctx_training.global_scale = 2 ** 21\n",
    "ctx_training.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шифрование данных \"Набор 1\" заняло 54 секунд\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_1_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_1_train]\n",
    "enc_y_1_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_1_train]\n",
    "t_end = time()\n",
    "print(f'Шифрование данных \"Набор 1\" заняло {int(t_end - t_start)} секунд')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шифрование данных \"Набор 2\" заняло 44 секунд\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_2_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_2_train]\n",
    "enc_y_2_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_2_train]\n",
    "t_end = time()\n",
    "print(f'Шифрование данных \"Набор 2\" заняло {int(t_end - t_start)} секунд')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шифрование данных \"Набор 3\" заняло 29 секунд\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_3_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_3_train]\n",
    "enc_y_3_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_3_train]\n",
    "t_end = time()\n",
    "print(f'Шифрование данных \"Набор 3\" заняло {int(t_end - t_start)} секунд')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шифрование данных \"Набор 4\" заняло 17 секунд\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_4_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_4_train]\n",
    "enc_y_4_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_4_train]\n",
    "t_end = time()\n",
    "print(f'Шифрование данных \"Набор 4\" заняло {int(t_end - t_start)} секунд')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шифрование данных \"Набор 5\" заняло 4 секунд\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_5_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_5_train]\n",
    "enc_y_5_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_5_train]\n",
    "t_end = time()\n",
    "print(f'Шифрование данных \"Набор 5\" заняло {int(t_end - t_start)} секунд')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шифрование данных \"Набор 6\" заняло 17 секунд\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_6_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_6_train]\n",
    "enc_y_6_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_6_train]\n",
    "t_end = time()\n",
    "print(f'Шифрование данных \"Набор 6\" заняло {int(t_end - t_start)} секунд')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шифрование данных \"Набор 7\" заняло 17 секунд\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_7_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_7_train]\n",
    "enc_y_7_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_7_train]\n",
    "t_end = time()\n",
    "print(f'Шифрование данных \"Набор 7\" заняло {int(t_end - t_start)} секунд')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шифрование данных \"Набор 8\" заняло 17 секунд\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_8_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_8_train]\n",
    "enc_y_8_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_8_train]\n",
    "t_end = time()\n",
    "print(f'Шифрование данных \"Набор 8\" заняло {int(t_end - t_start)} секунд')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шифрование данных \"Набор 9\" заняло 17 секунд\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_9_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_9_train]\n",
    "enc_y_9_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_9_train]\n",
    "t_end = time()\n",
    "print(f'Шифрование данных \"Набор 9\" заняло {int(t_end - t_start)} секунд')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLogisticRegression:\n",
    "    \n",
    "    def __init__(self, torch_lr):\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        # накапливаем градиент и подсчитываем количество итераций\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        enc_out = EncryptedLogisticRegression.sigmoid(enc_out)\n",
    "        return enc_out\n",
    "    \n",
    "    def backward(self, enc_x, enc_out, enc_y):\n",
    "        out_minus_y = (enc_out - enc_y)\n",
    "        self._delta_w += enc_x * out_minus_y\n",
    "        self._delta_b += out_minus_y\n",
    "        self._count += 1\n",
    "        \n",
    "    def update_parameters(self):\n",
    "        # обновляем параметры в соответствии с L2 регуляризацией, приняв α=1 и λ/m=0.05\n",
    "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
    "        self.bias -= self._delta_b * (1 / self._count)\n",
    "        # обнуляем накапливание градиента и счётчик итераций\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(enc_x):\n",
    "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
    "\n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    \n",
    "\n",
    "def enc_accuracy(model, x_test, y_test):\n",
    "    w = torch.tensor(model.weight)\n",
    "    b = torch.tensor(model.bias)\n",
    "    out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
    "    correct = torch.abs(y_test - out) < 0.5\n",
    "    return correct.float().mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_train(enc_model, enc_x_train, enc_y_train, x_test, y_test, data_name):\n",
    "    times = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        enc_model.encrypt(ctx_training)\n",
    "        t_start = time()\n",
    "        for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
    "            enc_out = enc_model.forward(enc_x)\n",
    "            enc_model.backward(enc_x, enc_out, enc_y)\n",
    "        enc_model.update_parameters()\n",
    "        t_end = time()\n",
    "        times.append(t_end - t_start)\n",
    "        \n",
    "        enc_model.decrypt()\n",
    "        accuracy = enc_accuracy(enc_model, x_test, y_test)\n",
    "\n",
    "            \n",
    "        print(f\"Точность модели, обученной на {data_name}, за эпоху {epoch + 1}: {accuracy}\")\n",
    "\n",
    "    print(f\"\\nСреднее время обучения модели, обученной на {data_name}, за эпоху: {int(sum(times) / len(times))} секунд\")\n",
    "    print(f\"Точность модели обученной на зашифрованных данных {data_name}: {accuracy}\")\n",
    "    \n",
    "    # if data_name == '\"Набор 1\"':\n",
    "    #     diff_accuracy = plain_accuracy_1 - accuracy\n",
    "    # elif data_name == '\"Набор 2\"':\n",
    "    #     diff_accuracy = plain_accuracy_2 - accuracy\n",
    "    # elif data_name == '\"Набор 3\"':\n",
    "    #     diff_accuracy = plain_accuracy_3 - accuracy\n",
    "    # elif data_name == '\"Набор 4\"':\n",
    "    #     diff_accuracy = plain_accuracy_4 - accuracy\n",
    "    # elif data_name == '\"Набор 5\"':\n",
    "    #     diff_accuracy = plain_accuracy_5 - accuracy   \n",
    "    # elif data_name == '\"Набор 6\"':\n",
    "    #     diff_accuracy = plain_accuracy_6 - accuracy\n",
    "    # elif data_name == '\"Набор 7\"':\n",
    "    #     diff_accuracy = plain_accuracy_7 - accuracy\n",
    "    # elif data_name == '\"Набор 8\"':\n",
    "    #     diff_accuracy = plain_accuracy_8 - accuracy\n",
    "    # elif data_name == '\"Набор 9\"':\n",
    "    #     diff_accuracy = plain_accuracy_9 - accuracy    \n",
    "    # print(f\"Разница между точностью модели обученной на зашифрованных и незашифрованных данных: {diff_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели, обученной на \"Набор 1\", за эпоху 1: 0.8602272868156433\n",
      "Точность модели, обученной на \"Набор 1\", за эпоху 2: 0.8602272868156433\n",
      "Точность модели, обученной на \"Набор 1\", за эпоху 3: 0.8602272868156433\n",
      "\n",
      "Среднее время обучения модели, обученной на \"Набор 1\", за эпоху: 388 секунд\n",
      "Точность модели обученной на зашифрованных данных \"Набор 1\": 0.8602272868156433\n"
     ]
    }
   ],
   "source": [
    "enc_lr_1 = EncryptedLogisticRegression(LogisticRegression(x_1_train.shape[1]))\n",
    "enc_model_1 = enc_train(enc_lr_1, enc_x_1_train, enc_y_1_train, x_1_test, y_1_test, '\"Набор 1\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели, обученной на \"Набор 2\", за эпоху 1: 0.8661764860153198\n",
      "Точность модели, обученной на \"Набор 2\", за эпоху 2: 0.8661764860153198\n",
      "Точность модели, обученной на \"Набор 2\", за эпоху 3: 0.8661764860153198\n",
      "\n",
      "Среднее время обучения модели, обученной на \"Набор 2\", за эпоху: 297 секунд\n",
      "Точность модели обученной на зашифрованных данных \"Набор 2\": 0.8661764860153198\n"
     ]
    }
   ],
   "source": [
    "enc_lr_2 = EncryptedLogisticRegression(LogisticRegression(x_2_train.shape[1]))\n",
    "enc_model_2 = enc_train(enc_lr_2, enc_x_2_train, enc_y_2_train, x_2_test, y_2_test, '\"Набор 2\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели, обученной на \"Набор 3\", за эпоху 1: 0.8333333134651184\n",
      "Точность модели, обученной на \"Набор 3\", за эпоху 2: 0.8333333134651184\n",
      "Точность модели, обученной на \"Набор 3\", за эпоху 3: 0.8333333134651184\n",
      "\n",
      "Среднее время обучения модели, обученной на \"Набор 3\", за эпоху: 219 секунд\n",
      "Точность модели обученной на зашифрованных данных \"Набор 3\": 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "enc_lr_3 = EncryptedLogisticRegression(LogisticRegression(x_3_train.shape[1]))\n",
    "enc_model_3 = enc_train(enc_lr_3, enc_x_3_train, enc_y_3_train, x_3_test, y_3_test, '\"Набор 3\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели, обученной на \"Набор 4\", за эпоху 1: 0.8571428656578064\n",
      "Точность модели, обученной на \"Набор 4\", за эпоху 2: 0.8571428656578064\n",
      "Точность модели, обученной на \"Набор 4\", за эпоху 3: 0.8571428656578064\n",
      "\n",
      "Среднее время обучения модели, обученной на \"Набор 4\", за эпоху: 124 секунд\n",
      "Точность модели обученной на зашифрованных данных \"Набор 4\": 0.8571428656578064\n"
     ]
    }
   ],
   "source": [
    "enc_lr_4 = EncryptedLogisticRegression(LogisticRegression(x_4_train.shape[1]))\n",
    "enc_model_4 = enc_train(enc_lr_4, enc_x_4_train, enc_y_4_train, x_4_test, y_4_test, '\"Набор 4\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели, обученной на \"Набор 5\", за эпоху 1: 0.8374999761581421\n",
      "Точность модели, обученной на \"Набор 5\", за эпоху 2: 0.8374999761581421\n",
      "Точность модели, обученной на \"Набор 5\", за эпоху 3: 0.8374999761581421\n",
      "\n",
      "Среднее время обучения модели, обученной на \"Набор 5\", за эпоху: 36 секунд\n",
      "Точность модели обученной на зашифрованных данных \"Набор 5\": 0.8374999761581421\n"
     ]
    }
   ],
   "source": [
    "enc_lr_5 = EncryptedLogisticRegression(LogisticRegression(x_5_train.shape[1]))\n",
    "enc_model_5 = enc_train(enc_lr_5, enc_x_5_train, enc_y_5_train, x_5_test, y_5_test, '\"Набор 5\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели, обученной на \"Набор 6\", за эпоху 1: 0.8464285731315613\n",
      "Точность модели, обученной на \"Набор 6\", за эпоху 2: 0.8464285731315613\n",
      "Точность модели, обученной на \"Набор 6\", за эпоху 3: 0.8464285731315613\n",
      "\n",
      "Среднее время обучения модели, обученной на \"Набор 6\", за эпоху: 111 секунд\n",
      "Точность модели обученной на зашифрованных данных \"Набор 6\": 0.8464285731315613\n"
     ]
    }
   ],
   "source": [
    "enc_lr_6 = EncryptedLogisticRegression(LogisticRegression(x_6_train.shape[1]))\n",
    "enc_model_6 = enc_train(enc_lr_6, enc_x_6_train, enc_y_6_train, x_6_test, y_6_test, '\"Набор 6\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели, обученной на \"Набор 7\", за эпоху 1: 0.8714285492897034\n",
      "Точность модели, обученной на \"Набор 7\", за эпоху 2: 0.8714285492897034\n",
      "Точность модели, обученной на \"Набор 7\", за эпоху 3: 0.8714285492897034\n",
      "\n",
      "Среднее время обучения модели, обученной на \"Набор 7\", за эпоху: 104 секунд\n",
      "Точность модели обученной на зашифрованных данных \"Набор 7\": 0.8714285492897034\n"
     ]
    }
   ],
   "source": [
    "enc_lr_7 = EncryptedLogisticRegression(LogisticRegression(x_7_train.shape[1]))\n",
    "enc_model_7 = enc_train(enc_lr_7, enc_x_7_train, enc_y_7_train, x_7_test, y_7_test, '\"Набор 7\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели, обученной на \"Набор 8\", за эпоху 1: 0.8714285492897034\n",
      "Точность модели, обученной на \"Набор 8\", за эпоху 2: 0.8714285492897034\n",
      "Точность модели, обученной на \"Набор 8\", за эпоху 3: 0.8714285492897034\n",
      "\n",
      "Среднее время обучения модели, обученной на \"Набор 8\", за эпоху: 88 секунд\n",
      "Точность модели обученной на зашифрованных данных \"Набор 8\": 0.8714285492897034\n"
     ]
    }
   ],
   "source": [
    "enc_lr_8 = EncryptedLogisticRegression(LogisticRegression(x_8_train.shape[1]))\n",
    "enc_model_8 = enc_train(enc_lr_8, enc_x_8_train, enc_y_8_train, x_8_test, y_8_test, '\"Набор 8\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
